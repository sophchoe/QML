{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5666165",
   "metadata": {},
   "source": [
    "# Hybrid quantum-classical auto encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78436a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sophie Choe sophchoe@pdx.edu\n",
    "Portland State University\n",
    "9/24/2021\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f47415",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is an implementation of the hybrid quantum-classical auto-encoder model outlined in \"Continuous-Variable \n",
    "quantum neural networks\" Physical Review Research 1, 033063, 2019. The encoder consists of six classical neural \n",
    "network layers and the decoder consists of three quantum neural network layers. Input vectors of length 3 are \n",
    "encoded in vectors of length 2, they are used as parameters of the Displacement gate paremeters, followed by the \n",
    "quantum decoder producing output vectors of length 3. \n",
    "\n",
    "The classical layers are implemented with Keras. The quantum layers are implemented with Pennylane. With the \n",
    "Pennylane qml.qnn.KerasLayer plug-in, the whole network is converted to a Keras model, and Keras loss function \n",
    "and optimizer are used for training.\n",
    "\n",
    "The loss function in the paper requires state vectors and probability, however Pennylane measurement module does \n",
    "not support state vector retrieval (as of 9/24/2021). Hence mean squared error from Keras is used instead on the \n",
    "output vectors of probability measurement. To get vectors of length 3, the cutoff dimension parameter is set to 3. \n",
    "\n",
    "It reaches around 70% training accuracy and around 75% evaluation accuracy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896652fd",
   "metadata": {},
   "source": [
    "Dependencies: anaconda-navigator==1.10.0 keras-nightly==2.5.0.dev2021032900 PennyLane==0.17.0 StrawberryFields==0.18.0 tensorflow @ file:///Users/uwe/miniconda3/conda-bld/tensorflow-split_1618075966251/work/tensorflow_pkg/tensorflow-2.4.0-cp38-cp38-macosx_10_9_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417078e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5487a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                       Create Data\n",
    "# ===================================================================================\n",
    "\n",
    "num_train = 100\n",
    "num_test = 20\n",
    "len_vector = 3\n",
    "\n",
    "np.random.seed(1)\n",
    "x_train = np.random.rand(num_train, len_vector)\n",
    "x_test = np.random.rand(num_test, len_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "143c9d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                       Classical Layers using Keras Sequential\n",
    "# ===================================================================================\n",
    "\n",
    "# Define first layer, hidden layers, and output layer with the output of two neurons\n",
    "\n",
    "keras.backend.set_floatx('float32')\n",
    "model = tf.keras.Sequential(\n",
    "                            [layers.Dense(5, input_shape=(3,), activation =\"elu\"),\n",
    "                             layers.Dense(5, activation =\"elu\"),\n",
    "                             layers.Dense(5, activation =\"elu\"),\n",
    "                             layers.Dense(5, activation =\"elu\"),\n",
    "                             layers.Dense(5, activation =\"elu\"),\n",
    "                             layers.Dense(5, activation =\"elu\"),\n",
    "                             layers.Dense(2, activation =\"elu\")]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0894c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                                Quantum Iterative Layer\n",
    "# ===================================================================================\n",
    "\n",
    "# Initialize weights to pass through the q_layer function. Tensor of size: num_layers x num_parameters  \n",
    "# Params for the Rotation gate, Squeezing gate, Displacement gate, and Kerr gate\n",
    "\n",
    "def init_weights(layers, modes, active_sd=0.0001, passive_sd=0.1):\n",
    "    \n",
    "    r1_weights = tf.random.normal(shape=[layers, modes], stddev=passive_sd)\n",
    "    s_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "    r2_weights = tf.random.normal(shape=[layers, modes], stddev=passive_sd)\n",
    "    dr_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "    k_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "\n",
    "    weights = tf.concat([r1_weights, s_weights, r2_weights, dr_weights, k_weights], axis=1)\n",
    "    weights = tf.Variable(weights)\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Construct a quantum layer with initialized weights as variables\n",
    "\n",
    "def q_layer(v):\n",
    "    qml.Rotation(v[0], wires=0)\n",
    "    qml.Squeezing(v[1], 0.0, wires=0)\n",
    "    qml.Rotation(v[2], wires=0)\n",
    "    qml.Displacement(v[3], 0.0, wires=0)\n",
    "    qml.Kerr(v[4], wires=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6535be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                                Quantum Circuit\n",
    "# ===================================================================================\n",
    "\n",
    "# Use the output of the classical layers to initialize the quantum layers with the Displacement gate\n",
    "# Iterate the quantum layers\n",
    "\n",
    "num_modes = 1\n",
    "num_basis = 3\n",
    "\n",
    "dev = qml.device(\"strawberryfields.fock\", wires=num_modes, cutoff_dim=num_basis) # select a devide \n",
    "\n",
    "@qml.qnode(dev, interface = \"tf\")\n",
    "def quantum_nn(inputs, var):\n",
    "    \n",
    "    # Inputs: the output of classical layers as displacement gate parameters\n",
    "    qml.Displacement(inputs[0], inputs[1], wires=0)    \n",
    "\n",
    "    # quantum layers\n",
    "    for v in var:\n",
    "        q_layer(v)\n",
    "\n",
    "    return qml.probs(wires=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3d72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                             Hybrid Model\n",
    "# ===================================================================================\n",
    "\n",
    "\"\"\"\n",
    "Add the quantum layer to the classical to create a hybrid model\n",
    "    1. initialize weights for quantum layers\n",
    "    2. create a dictionary of weight shape to pass as one of the variables to covert to keras layer\n",
    "    3. convert the quantum layer to a Keras layer\n",
    "    4. add to the classical sequential model\n",
    "\"\"\"\n",
    "\n",
    "num_layers = 4\n",
    "num_modes = 1\n",
    "\n",
    "weigths = init_weights(num_layers, num_modes)\n",
    "shape_tup = weigths.shape\n",
    "weight_shapes = {'var': shape_tup}\n",
    "qlayer = qml.qnn.KerasLayer(quantum_nn, weight_shapes, output_dim=4)\n",
    "model.add(qlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf0e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                           Loss Function and Optimizer\n",
    "# ===================================================================================\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "#opt = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
    "\n",
    "model.compile(opt, loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b23d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================================\n",
    "#                                    Training\n",
    "# ===================================================================================\n",
    "\n",
    "model.fit(x_train, \n",
    "          x_train,\n",
    "          epochs=200,\n",
    "          batch_size=24,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f164ec7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0941 - accuracy: 0.7500\n",
      "test loss, test acc: [0.09412109851837158, 0.75]\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================================\n",
    "#                                    Evalutation\n",
    "# ===================================================================================\n",
    "\n",
    "results = model.evaluate(x_test, x_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce47a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
